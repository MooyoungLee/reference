{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction\n",
    "\n",
    "### Objective:\n",
    "\n",
    "- Comparing PCA, LDA, QDA\n",
    "\n",
    "10/5/2018<br>\n",
    "Mooyoung Lee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data: Boston House Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.593761</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.596783</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.647423</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.593761   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.596783   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.647423   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT      target  \n",
       "count  506.000000  506.000000  \n",
       "mean    12.653063   22.532806  \n",
       "std      7.141062    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      6.950000   17.025000  \n",
       "50%     11.360000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "data = datasets.load_boston()\n",
    "df = pd.DataFrame(data.data, columns = data.feature_names)\n",
    "df['target'] = data.target\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      0\n",
       "CHAS       0\n",
       "NOX        0\n",
       "RM         0\n",
       "AGE        0\n",
       "DIS        0\n",
       "RAD        0\n",
       "TAX        0\n",
       "PTRATIO    0\n",
       "B          0\n",
       "LSTAT      0\n",
       "target     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check distribution\n",
    "\n",
    "- data transformation step will be skipped for this study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "\n",
    "# for col in list(df):\n",
    "#     plt.figure()\n",
    "#     sns.distplot(df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model: RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML\\Anaconda3\\envs\\kerasGPU\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV result :\n",
      "    MSE(Train)  MSE(Test)\n",
      "0       2.491      6.861\n",
      "1       2.162      6.449\n",
      "2       2.227     16.533\n",
      "3       1.988      8.957\n",
      "4       1.876     22.440\n",
      "5       2.672     22.048\n",
      "6       2.427     20.213\n",
      "7       2.716      5.622\n",
      "8       1.700      7.140\n",
      "9       1.713     11.500\n",
      "\n",
      "CV average :\n",
      " MSE(Train)     2.1972\n",
      "MSE(Test)     12.7763\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "y = df['target'].values\n",
    "X = df.drop(['target'], axis = 1).values\n",
    "\n",
    "reg = RandomForestRegressor()\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "cv_obj = KFold(n_splits = 10, shuffle = True)\n",
    "\n",
    "result = []\n",
    "for train_index, test_index in cv_obj.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # train eval\n",
    "    reg.fit(X_train, y_train)\n",
    "    MSE_train = mean_squared_error(y_true = y_train, y_pred = reg.predict(X_train))\n",
    "    \n",
    "    # test eval\n",
    "    y_hat = reg.predict(X_test)\n",
    "    MSE = mean_squared_error(y_true = y_test, y_pred = y_hat)\n",
    "    result.append([MSE_train, MSE])\n",
    "\n",
    "    \n",
    "# Result Summary\n",
    "result_fold = pd.DataFrame(np.round(result,3), columns = ['MSE(Train)','MSE(Test)'])\n",
    "print('\\nCV result :\\n', result_fold)\n",
    "print('\\nCV average :\\n', result_fold.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model shows some overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'KFold Evaluation')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAETCAYAAAA7wAFvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAHoZJREFUeJzt3XuYFPWd7/H3xxHlKioXRRAHjXcQxMHL6okYLygmenJWjRovh0uIiQayidn1rFHR3Xh0zcX45OLjiRglisYcTUxEItGDZmNWBR0BIXgLRhZERAVEUQa+54+qmW3GuRTDdPUw9Xk9Tz/TXVVdv283w3y6fr+qXysiMDOz4tqh0gWYmVllOQjMzArOQWBmVnAOAjOzgnMQmJkVnIPAzKzgHATWqUiqlhSSdmxm/VRJv+hINbXD/l+UNLoc+7ZicBBYxUhaKumkksfnSnpX0vElfzzfL7m9UOZ6Rkva3KjN9yUdU852t4akn0v619JlEXFoRMypUEnWCZTlE4rZ1pJ0MfB94PSIeEpSdbpq14ioy7GU5RExKMf2zCrORwRWcZImAd8DxkTEUxm230HStyW9LuktSXdJ6t3MtkMkPSFpnaTZQN821niupLmNlv2DpIfS+6dLel7SWklvSJrawr4aHwlt0V0l6X5Jb0paI+lJSYemyycBXwT+MT1S+W3j/UnaWdLNkpant5sl7ZyuGy1pmaRvpu/bCknj2vJ+WOfiILBK+wrwL8CJETG3tY1T/zO9nQDsC/QEftTMtvcA80gC4F+Ai9tY50PAgZL2L1l2frp/gPXARcCuwOnAVyT99za29QiwP9AfeA64GyAibkvv/1tE9IyIzzXx3CuBo4ERwHDgSODbJev3BHoDA4EJwI8l7dbGOq2TcBBYpZ0M/AewoJn1b0t6L71dni77IvD9iHgtIt4H/hdwbuPBWEmDgVHAVRHxUUQ8Cfy2lXr2Kmmv/tYjIj4AfgOcl+57f+AgkoAgIuZExIKI2BwR84EZwPFb+V6Q7mtaRKyLiI+AqcDw5o54mvBF4LqIeCsiVgHXAheWrN+Yrt8YETOB94ED21KndR4OAqu0S4ADgJ9JUhPr+0bEruntu+myvYDXS7Z5nWS8a49Gz90LeDci1jfatiXLS9qrv9U//x7SICA5Gvh1GhBIOkrS/5O0StKa9HVtdTeUpCpJN0h6VdJaYGm6Kuu+mnpv9ip5vLrRmMsHJEdUVmAOAqu0t4ATgf8G/CTjc5YD+5Q8HgzUASsbbbcC2E1Sj0bbttWjQF9JI0gC4Z6SdfeQHB3sHRG9gVuBpoINkm6k7iWP9yy5fz5wJnASSRdOdbq8fl+tTRfc1HuzvJXnWME5CKziImI58BngVEk/yPCUGcA/pAPBPYHrgfsan10UEa8Dc4FrJe0k6TigqX71rHXWAb8CbgJ2B2aXrO4FvBMRGyQdSfIHvTm1JF1ZXSTVAGc12s9HwGqSsLi+0XNXkoyLNGcG8G1J/ST1Ba4Gcr1uwrY/DgLrECLiDZIwOEvS/25l82nAdOBJ4K/ABuBrzWx7PnAU8A5wDXBXK/veq4nrCP6+ZP09JJ/W728UPF8FrpO0juSP7y9baOMqYD/gXZI+/NIji7tIunP+E1hEMn5S6nbgkHTs4tdN7PtfScJvPsm4y3PpMrNmyV9MY2ZWbD4iMDMrOAeBmVnBOQjMzArOQWBmVnAOAjOzgtsuZh/t27dvVFdXV7oMM7Ptyrx5896OiH6tbbddBEF1dTVz52adj8zMzAAktTalCuCuITOzwnMQmJkVnIPAzKzgtosxAjPbPm3cuJFly5axYcOGSpfSqXXt2pVBgwbRpUuXNj3fQWBmZbNs2TJ69epFdXU1TX/dhG2riGD16tUsW7aMIUOGtGkf7hoys7LZsGEDffr0cQiUkST69OmzTUddDgIzKyuHQPlt63vsIDAzKziPEVixTW3lO+GnrsmnjoKovuLhdt3f0htOb3UbSVxwwQVMnz4dgLq6OgYMGMBRRx3F7373O1auXMmECRN444032LhxI9XV1cycOZOlS5dy8MEHc+CBBzbs6xvf+AYXXXQREcGJJ57IHXfcwZlnngnAm2++SVVVFf36JRfyPvPMM+y0006ZXse4ceO44oortmirsZtvvpk+ffpw4YUXZtrn1nAQmFmn1qNHDxYuXMiHH35It27dmD17NgMHDmxYf/XVV3PyySczZcoUAObPn9+wbr/99qO2tvYT+5w5cybDhw9nn332aVg/depUevbsyeWXX/6J7SOCiGCHHZruhLnjjjtafR0TJ07k05/+dFmCwF1DZtbpnXbaaTz8cHI0MmPGDM4777yGdStWrGDQoEENjw877LBW93f33Xc3HAk055VXXmHo0KFccskljBw5khUrVjBp0iRqamo49NBDue666xq2Pe6446itraWuro5dd92VK664guHDh3PMMcfw1ltvAdCzZ08GDhzIc889t1WvPQsHgZl1eueeey733nsvGzZsYP78+Rx11FEN6y699FImTJjACSecwHe+8x2WL1/esO7VV19lxIgRDbc//vGPAPzpT3/iiCOOaLXdRYsWMWHCBJ5//nkGDhzIDTfcwNy5c3nhhReYPXs2ixYt+sRz1qxZw/HHH88LL7zAMcccw7Rp0xrW1dTUNNTQntw1ZFZpHqcou8MOO4ylS5cyY8YMxo4du8W6MWPG8NprrzFr1iweeeQRDj/8cBYuXAg03zX0zjvv0KtXr1bb3W+//Rg1alTD4xkzZnD77bdTV1fH8uXLWbRoEYcccsgWz+nWrRunnXYaAEccccQWf/j79+/P0qVLM7/urHxEYGaFcMYZZ3D55Zdv0S1Ub/fdd+f8889n+vTpjBo1iieffLLFfe24445s3ry51TZ79OjRcP/ll1/mhz/8IY8//jjz58/n1FNPbfLc/9IB5qqqKurq6hoeb9iwgW7durXa7tZyEJhZIYwfP56rr76aYcOGbbH88ccf54MPPgBg3bp1vPrqqwwePLjFfR144IG89tprW9X+2rVr6dWrF7vssgsrVqzg97///da9AOCll15i6NChW/281rhryMxyk+V0z3IZNGhQw5lBpebNm8dll13W8Cl/4sSJjBo1iqVLlzaMEdQbP348kydP5vTTT2fOnDl86lOfytz+yJEjOeSQQxg6dCj77rsvxx577Fa/hj//+c9cf/31W/281igi2n2n7a2mpib8xTRWFh2hf74j1FAmixcv5uCDD650Ge1uxYoVXHTRRcyePTu3Np999ll+8pOfNHuqaVPvtaR5EVHT2r7dNWRmtpUGDBjAl770JdauXZtbm++88w7XXnttWfbtriEzszY455xzcm1vzJgxZdu3jwjMzArOQWBmVnAOAjOzgnMQmJkVnAeLzSw/rZ0qu9X7a/3U2u1hGmqAadOmMXbsWPbcc08Azj77bG688Ub23XffzPtoKweBmXVqHWEa6iymTZvGyJEjG4Lgkksu4aabbuKnP/1pm/a3Ndw1ZGadXiWmoQa48847OfLIIxkxYgRf/epX2bx5M3V1dVx44YUMGzaMoUOHcsstt3DfffdRW1vLF77wBUaMGMHHH3/M6NGjmTVrFps2bWrDK946DgIz6/QqMQ31woULefDBB3nqqacavmvg3nvvZd68ebz99tssWLCAhQsXctFFFzUEQH0g7LTTTlRVVVFdXd0wE2o5la1rSNLewF3AnsBm4LaI+KGk3YH7gGpgKXBORLxbrjrMzCoxDfUf/vAHnn32WWpqkhkePvzwQ/bee2/GjBnDkiVLmDJlCmPHjuWUU05pdh/9+/dn+fLlDB8+fGtf8lYp5xFBHfDNiDgYOBq4VNIhwBXAYxGxP/BY+tjMrKzynoY6Ihg/fjy1tbXU1tayZMkSrrrqKvr06cP8+fM57rjjuOWWW/jyl7/c7D7KNe10Y2U7IoiIFcCK9P46SYuBgcCZwOh0szuBOcA/lasOM8uoE09+B8nMob1792bYsGHMmTOnYfnjjz/O0UcfTffu3bd6GuqWZh896aSTOOuss5gyZQp9+/Zl9erVrF+/nm7dutG1a1fOPvtshgwZwiWXXAJAr169WLdu3Rb7ePnllzn00EPb/qIzyuWsIUnVwOHA08AeaUgQESsk9c+jBjPrACoYJnlPQz1s2DCuueYaTjrpJDZv3kyXLl249dZbqaqqYsKECUQEkrjxxhsBGDduHBMnTqRbt24888wzvP322/Tu3bvhdNRyKvs01JJ6Ak8A34mIByS9FxG7lqx/NyJ2a+J5k4BJAIMHDz7i9ddfL2udVlAd4VNwR6ihTHV4Guq2u+mmm+jfvz8XX3xxpu077DTUkroA/xe4OyIeSBevlDQgXT8AeKup50bEbRFRExE1eSSimVlWeUxD3adPHy644IKy7b9U2YJAkoDbgcUR8f2SVQ8B9RF3MfCbctVgZlYu55xzDrvsskvZ9j9+/HiqqqrKtv9S5RwjOBa4EFggqf78q38GbgB+KWkC8Dfg7DLWYGYVVt8XbuWzrV385Txr6N+B5v71TyxXu2bWcXTt2pXVq1fTp08fh0GZRASrV6+ma9eubd6H5xoys7IZNGgQy5YtY9WqVZUupVPr2rXrFtNkbC0HgZmVTZcuXRgyZEily7BWeK4hM7OCcxCYmRWcg8DMrOAcBGZmBecgMDMrOAeBmVnBOQjMzArOQWBmVnAOAjOzgnMQmJkVnIPAzKzgHARmZgXnIDAzKzgHgZlZwTkIzMwKzkFgZlZwDgIzs4JzEJiZFZyDwMys4BwEZmYF12IQSKqS9Ie8ijEzs/y1GAQRsQn4QFLvnOoxM7Oc7Zhhmw3AAkmzgfX1CyNictmqMjOz3GQJgofTm5mZdUKtBkFE3ClpJ+CAdNGSiNhY3rLMzCwvrQaBpNHAncBSQMDeki6OiCfLW5qVzdRWhnymrsmnDjPrELJ0DX0POCUilgBIOgCYARxRzsLMzCwfWa4j6FIfAgAR8RLQpXwlmZlZnrIcEcyVdDswPX38RWBe+UoyM7M8ZQmCrwCXApNJxgieBH5SzqLMzCw/LQaBpCrg9oi4APh+PiWZmVmeslxZ3C89fdTMzDqhLF1DS4E/SXqILa8s9hGCmVknkCUIlqe3HYBe5S3HzMzylmWMoGdEfCuneszMLGdZxghGtmXHkqZJekvSwpJlUyX9p6Ta9Da2Lfs2M7P2k6VrqDYdH7ifLccIHmjleT8HfgTc1Wj5DyLiu1tTpJmZlU+WINgdWA18pmRZAC0GQUQ8Kam6zZWZmVkussw+Oq6d27xM0kXAXOCbEfFuO+/fzMy2QrNjBJJ+WXL/xkbrHm1jez8F9gNGACtIJrRrrv1JkuZKmrtq1ao2NmdmZq1pabB4/5L7Jzda168tjUXEyojYFBGbgf8DHNnCtrdFRE1E1PTr16bmzMwsg5aCINq4rlmSBpQ8/DywsLltzcwsHy2NEXSXdDhJWHRL7yu9dWttx5JmAKOBvpKWAdcAoyWNIAmSpcCXt6l6MzPbZi0FwQr+a6K5N9ly0rk3W9txRJzXxOLbs5dmZmZ5aDYIIuKEPAsxM7PKyPINZWZm1ok5CMzMCs5BYGZWcM2OEUhqcbK5iHiu/csxM7O8tXTWUP1Vv12BGuAFklNHDwOeBo4rb2lmZpaHZruGIuKE9Myh14GR6VW+RwCHA6/kVaCZmZVXljGCgyJiQf2DiFhIMleQmZl1AlmmoV4s6WfAL0iuCL4AWFzWqszMLDdZgmAc8BVgSvr4SZJZRM3MrBPI8n0EGyTdCsyMiCU51GRmZjlqdYxA0hlALTArfTwi/epKMzPrBLIMFl9D8r0B7wFERC1QXcaazMwsR1mCoC4i1pS9EjMzq4gsg8ULJZ0PVEnaH5gMPFXesszMLC9Zjgi+BhwKfATcA6wBvl7OoszMLD8tHhFIqgKujYhvAVfmU5KZmeWpxSOCiNgEHJFTLWZmVgFZxgieT08XvR9YX78wIh4oW1VmZpabLEGwO7Aa+EzJsgAcBGZmnUCWK4vH5VGImZlVRqtBIKkrMIHkzKGu9csjYnwZ6zIzs5xkOX10OrAnMAZ4AhgErCtnUWZmlp8sQfCpiLgKWB8RdwKnA8PKW5aZmeUlSxBsTH++J2ko0BvPNWRm1mlkOWvoNkm7AVcBDwE9gavLWpWZmeUmy1lDP0vvPgHsW95yzMwsb1nOGmry039EXNf+5ZiZGQBTe7eyvv0mhc7SNbS+5H5X4LP4O4vNzDqNLF1D3yt9LOm7JGMFZmbWCWQ5a6ix7niswMys08gyRrCAZG4hgCqgH+DxATOzTiLLGMFnS+7XASsjoq5M9ZiZWc6yBEHj6SR2kdTwICLeadeKzMwsV1mC4Dlgb+BdQMCuwN/SdYHHC8zMtmtZBotnAZ+LiL4R0Yekq+iBiBgSEQ4BM7PtXJYgGBURM+sfRMQjwPHlK8nMzPKUJQjelvRtSdWS9pF0Jck3lrVI0jRJb0laWLJsd0mzJb2c/txtW4o3M7NtlyUIziM5ZfRB4NdA/3RZa34OnNpo2RXAYxGxP/BY+tjMzCooy5XF7wBTANJP8O9FRLT8LIiIJyVVN1p8JjA6vX8nMAf4p8zVmplZu2v2iEDS1ZIOSu/vLOlx4BVgpaST2tjeHhGxAiD92b+N+zEzs3bSUtfQF4Al6f2L0237kwwUX1/mupA0SdJcSXNXrVpV7ubMzAqrpSD4uKQLaAwwIyI2RcRisl1/0JSVkgYApD/fam7DiLgtImoioqZfv35tbM7MzFrTUhB8JGmopH7ACcCjJeu6t7G9h0iOLkh//qaN+zEzs3bS0if7KcCvSM4Y+kFE/BVA0ljg+dZ2LGkGycBwX0nLgGuAG4BfSppAcnXy2dtUvZmZbbNmgyAingYOamL5TGDmJ5/xie2aO8X0xMzVmZlZ2bXl+wjMzKwTcRCYmRWcg8DMrOAynQYq6e+A6tLtI+KuMtVkZmY5yvJVldOB/YBaYFO6OAAHgZlZJ5DliKAGOCTL/EJmmU3tnWGbNeWvw8wyjREsBPYsdyFmZlYZWY4I+gKLJD0DfFS/MCLOKFtVZmaWmyxBMLXcRZiZWeVk+T6CJ/IoxMzMKqPVMQJJR0t6VtL7kj6WtEnS2jyKMzOz8ssyWPwjkq+mfBnoBkxMl5mZWSeQ6YKyiHhFUlVEbALukPRUmesyM7OcZAmCDyTtBNRK+jdgBdCjvGWZmVlesnQNXZhudxmwHtgb+PtyFmVmZvnJctbQ65K6AQMi4tocajIzsxxlOWvocyTzDM1KH4+Q9FC5CzMzs3xk6RqaChwJvAcQEbUkM5GamVknkCUI6iLCs3+ZmXVSWc4aWijpfKBK0v7AZMCnj5qZdRJZjgi+BhxKMuHcDGAt8PVyFmVmZvnJctbQB8CV6c3MzDqZZoOgtTODPA21mXVarX1xUif70qSWjgiOAd4g6Q56GlAuFZmZWa5aCoI9gZNJJpw7H3gYmBERL+ZRWLsrWMKbmWXV7GBxRGyKiFkRcTFwNPAKMEfS13KrzszMyq7FwWJJOwOnkxwVVAO3AA+UvywzM8tLS4PFdwJDgUeAayNiYW5VmZlZblo6IriQZLbRA4DJUsNYsYCIiF3KXFvn09o4BXiswsxy12wQRESWi83MzGw75z/2ZmYF5yAwMys4B4GZWcE5CMzMCs5BYGZWcA4CM7OCy/LFNGZm+fCcYBVRkSCQtBRYB2wi+SrMmkrUYWZmlT0iOCEi3q5g+2ZmhscIzMwKr1JBEMCjkuZJmlShGszMjMp1DR0bEcsl9QdmS/pLRDxZukEaEJMABg8eXIkazcwKoSJHBBGxPP35FvAgcGQT29wWETURUdOvX7+8SzQzK4zcg0BSD0m96u8DpwD+rgMzswqpRNfQHsCD6fcb7AjcExGzKlCHmZlRgSCIiNeA4Xm3a2ZmTfPpo2ZmBecgMDMrOAeBmVnBOQjMzArOQWBmVnAOAjOzgnMQmJkVnIPAzKzgHARmZgXnIDAzKzgHgZlZwTkIzMwKzkFgZlZwDgIzs4JzEJiZFZyDwMys4Cr15fVmVkDVVzzc4vqlXXMqxLbgIDArM//xs46uUwRBa//RwP/ZzMya0ymCwMxa5g9L1hIPFpuZFZyPCNpRR+gL9ic/M9taPiIwMys4HxFYWXSEoyMzy8ZBYJ2Wu8nMsnHXkJlZwfmIwMwKpaMcKXak7lMfEZiZFZyDwMys4BwEZmYF5yAwMys4B4GZWcE5CMzMCs5BYGZWcA4CM7OCcxCYmRWcg8DMrOAcBGZmBVeRIJB0qqQlkl6RdEUlajAzs0TuQSCpCvgxcBpwCHCepEPyrsPMzBKVOCI4EnglIl6LiI+Be4EzK1CHmZkBioh8G5TOAk6NiInp4wuBoyLiskbbTQImpQ8PBJZsY9N9gbe3cR/bqiPUAB2jjo5QA3SMOjpCDdAx6ugINUDHqKM9atgnIvq1tlElvo9ATSz7RBpFxG3Abe3WqDQ3Imraa3/baw0dpY6OUENHqaMj1NBR6ugINXSUOvKsoRJdQ8uAvUseDwKWV6AOMzOjMkHwLLC/pCGSdgLOBR6qQB1mZkYFuoYiok7SZcDvgSpgWkS8mEPT7dbNtA06Qg3QMeroCDVAx6ijI9QAHaOOjlADdIw6cqsh98FiMzPrWHxlsZlZwTkIzMwKzkFgZlZwlbiOoOwkHURytfJAkmsUlgMPRcTiihZWAel7MRB4OiLeL1l+akTMyrGOI4GIiGfTKUVOBf4SETPzqqGJmu6KiIsq1X5aw3EkV9svjIhHc2rzKGBxRKyV1A24AhgJLAKuj4g1OdUxGXgwIt7Io71maqg/c3F5RPxB0vnA3wGLgdsiYmOOtewHfJ7k9Po64GVgRh7/Hp1usFjSPwHnkUxdsSxdPIjkH/veiLihUrXVkzQuIu7IoZ3JwKUkv9QjgCkR8Zt03XMRMbLcNaRtXUMyt9SOwGzgKGAOcBLw+4j4Tg41ND5FWcAJwOMAEXFGuWtI63gmIo5M73+J5N/nQeAU4Ld5/H5KehEYnp7BdxvwAfAr4MR0+f8odw1pHWuA9cCrwAzg/ohYlUfbJTXcTfJ72R14D+gJPEDyXigiLs6pjsnA54AngLFALfAuSTB8NSLmlLWAiOhUN+AloEsTy3cCXq50fWktf8upnQVAz/R+NTCXJAwAns/x9S4gOVW4O7AW2CVd3g2Yn1MNzwG/AEYDx6c/V6T3j8/xvXi+5P6zQL/0fg9gQU41LC59Xxqtq83zvSDpnj4FuB1YBcwCLgZ65VTD/PTnjsBKoCp9rLx+N9P2FpS03R2Yk94fnMf/1c7YNbQZ2At4vdHyAem6XEia39wqYI+cyqiKtDsoIpZKGg38StI+ND3VR7nURcQm4ANJr0bE2rSmDyXl9W9SA0wBrgS+FRG1kj6MiCdyar/eDpJ2I/kDqEg/AUfEekl1OdWwsOSo9AVJNRExV9IBQG5dISRdhZuBR4FHJXUhOXI8D/gu0OocOe1gh7R7qAfJH+DewDvAzkCXHNovtSOwKW27F0BE/C19X8recGfzdeAxSS8D9X2Pg4FPAZc1+6z2twcwhuTwrpSAp3Kq4U1JIyKiFiAi3pf0WWAaMCynGgA+ltQ9Ij4AjqhfKKk3OYVz+gfnB5LuT3+upDK//72BeSS/ByFpz4h4U1JP8gvnicAPJX2bZFKzP0t6g+T/y8ScaoBGrzeS/viHgIfSsYs83A78heSI9UrgfkmvAUeTdC/n5WfAs5L+A/g0cCOApH4kwVRWnW6MAEDSDiQDcANJftmWAc+mn0rzquF24I6I+Pcm1t0TEefnUMMgkk/jbzax7tiI+FO5a0jb2jkiPmpieV9gQEQsyKOORm2fDhwbEf+cd9tNkdQd2CMi/ppjm72AfUkCcVlErMyr7bT9AyLipTzbbKaOvQAiYrmkXUnGrv4WEc/kXMehwMEkJw78Jde2O2MQmJlZdr6OwMys4BwEZmYF5yCwwpK0p6R7Jb0qaZGkmZIOkPRXSQc22vZmSf/YxD5ukvSipJtaaGeqpMubWF4taWH7vBqztuuMZw2ZtUqSSC7kujMizk2XjSA52+tekgsQr02X7wCcBRzbxK6+THItwCcGw822Fz4isKI6AdgYEbfWL4iI2oj4I8lVrueWbPtpYGlEbHFtSnq1cg/gaUlfkLSPpMckzU9/Dm7cqKQjJL0g6c8kVxWbVZyDwIpqKMn5/J8QEfOBzZKGp4vOJQmHxtudAXwYESMi4j7gR8BdEXEYcDdwSxO7vwOYHBHHtMNrMGsXDgKzps0AzpW0I8kEhvdneM4xwD3p/enAcaUr0wvodi25mnl6O9Vqtk0cBFZUL1JylXMTZgDnkFxcND8i3mpDG40v0lETy8wqzkFgRfU4sHM6AygAkkZJOh4gIl4FVgM30ES3UDOe4r/GFr4IbHFVeUS8B6xJp56u38as4hwEVkiRXFL/eeDk9PTRF4GpJN9dUW8GcBDJ2UVZTAbGpRMOXkgyyV1j44Afp4PFH7axfLN25SkmzMwKzkcEZmYF5yAwMys4B4GZWcE5CMzMCs5BYGZWcA4CM7OCcxCYmRWcg8DMrOD+P8bphdERJW7vAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_fold.plot(kind='bar')\n",
    "plt.legend(['MSE(Train)','MSE(Test)'])\n",
    "plt.xlabel('CV fold')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('KFold Evaluation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA, LDA, & QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: (array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]),)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-30fc85d8dbe4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mlda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearDiscriminantAnalysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mX_lda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mqda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mQuadraticDiscriminantAnalysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kerasGPU\\lib\\site-packages\\sklearn\\discriminant_analysis.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    428\u001b[0m         \"\"\"\n\u001b[0;32m    429\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpriors\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# estimate priors from sample\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kerasGPU\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[1;34m(*ys)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[0m_unique_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FN_UNIQUE_LABELS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_unique_labels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown label type: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[0mys_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_unique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: (array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]),)"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "# y = np.array(y, dtype = np.float64)\n",
    "\n",
    "pca = PCA(n_components = 3)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(n_components = 3)\n",
    "X_lda = lda.fit(X,y).transform(X)\n",
    "\n",
    "qda = QuadraticDiscriminantAnalysis(n_components = 3)\n",
    "X_qda = qda.fit_transform(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
